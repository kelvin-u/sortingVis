# sortingVisualizer:

![cognisign logo](https://github.com/kelvin-u/sortingVisualizer/blob/main/sorting.gif?raw=true)




## Table of Contents

- [About](#about)
- [Key Features](#key-features)
- [Technical Overview](#technical-overview)
- [Installation](#installation)
- [Contact](#contact)
- [License](#license)

## About

CogniSign is a revolutionary project that aims to bridge communication gaps and enhance educational opportunities for the deaf community. By combining advanced neural network architectures and computer vision techniques, CogniSign enables real-time recognition of American Sign Language (ASL) gestures, transforming them into letters and words.

## Key Features

- Real-time hand gesture detection and recognition.
- Integration of OpenCV for hand region segmentation and noise reduction.
- Custom-built neural network architecture designed for ASL recognition.
- Seamless transformation of ASL gestures into letters and words.

## Technical Overview

CogniSign's technical architecture revolves around the synergy of computer vision and machine learning. The core components include:

- **OpenCV Integration:** Captures and processes real-time video feed, performs hand detection, and isolates the hand region.
- **Neural Network Architecture:** A meticulously designed neural network with convolutional and recurrent layers trained on an ASL dataset for accurate recognition.
- **Real-time Processing:** Combines OpenCV and the neural network to instantly decipher ASL gestures, presenting them as letters and words.

## Installation

1. Clone this repository:
   ```https://github.com/kelvin-u/CogniSign.git```

2. Run the Python file ```main.py```

3. Enjoy the experience of testing your skills in American Sign Language! (see how accurate it is :slightly_smiling_face:)

## Contact
Connect with me :wave:

[LinkedIn](https://www.linkedin.com/in/kelvin-u/) | [Email](mailto:yukaiwenn@gmail.com) | [Website](https://kelvinu.ca/)

## License
This project is licensed under the [MIT License](LICENSE)



